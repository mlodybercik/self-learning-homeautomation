{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from abc import ABC, abstractmethod\n",
    "from datetime import datetime, time as Time, timedelta\n",
    "\n",
    "MAX_STATES = 6\n",
    "N_OF_STATES = 2**MAX_STATES\n",
    "\n",
    "STATE_IS = 0\n",
    "STATE_SHOULD_BE = 1\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "def float_to_bool(action: np.ndarray):\n",
    "    return action >= 0.5\n",
    "\n",
    "def bool_to_float(state: np.ndarray):\n",
    "    return state.astype(float)\n",
    "\n",
    "def reward_function(n: int, lambda_: float = 1) -> float:\n",
    "    return (lambda_ * np.e)**(-lambda_*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HomeAssistantTrainingEnvironment:\n",
    "    state: np.ndarray\n",
    "    timestep: int\n",
    "\n",
    "    def __init__(self, episodes: t.List[t.Tuple[np.ndarray, np.ndarray]]):\n",
    "        self.episodes = episodes\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = np.zeros(shape=(MAX_STATES, ), dtype=float)\n",
    "        self.timestep = 0\n",
    "        return self.state\n",
    "    \n",
    "    def reward(self, action: np.ndarray):\n",
    "        _, state_should_be = self.episodes[self.timestep]\n",
    "        return -np.sum(np.square(action - state_should_be))\n",
    "        # action\n",
    "        # return reward_function()\n",
    "\n",
    "    \n",
    "    \n",
    "    def step(self, action: np.ndarray):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            action should be a binary tensor with ones in places where the action should be flipped\n",
    "\n",
    "        returs:\n",
    "            next state - next_state of the system\n",
    "            reward -\n",
    "            done - \n",
    "        \"\"\"\n",
    "        \n",
    "        # performed_action = float_to_bool(action)\n",
    "        reward = self.reward(action)\n",
    "        \n",
    "        self.timestep += 1\n",
    "        try:\n",
    "            return self.episodes[self.timestep][STATE_IS], reward, False\n",
    "        except IndexError:\n",
    "            return self.episodes[self.timestep - 1][STATE_IS], reward, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dnn_network(parameters: t.Sequence[str], values: t.Sequence[str]):\n",
    "    inputs = {}\n",
    "    outputs = {}\n",
    "\n",
    "    for parameter in parameters:\n",
    "        inputs[parameter] = tf.keras.layers.Input(shape=(1,), name=parameter)\n",
    "    \n",
    "    input = tf.keras.layers.Concatenate(axis=-1)(list(inputs.values()))\n",
    "    proper_input = tf.keras.layers.Flatten()(input)\n",
    "    layer = tf.keras.layers.Dense(128, activation='relu')(proper_input)\n",
    "    layer = tf.keras.layers.Dense(64, activation='relu')(layer)\n",
    "    \n",
    "    for value in values:\n",
    "        outputs[value] = tf.keras.layers.Dense(1, activation='tanh')(layer)\n",
    "\n",
    "    return tf.keras.models.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "\n",
    "    def __init__(self, num_actions=MAX_STATES, gamma=0.99):\n",
    "        self.num_actions = num_actions\n",
    "        self.model = QNetwork(num_actions)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        self.model.compile(loss='mse', optimizer=self.optimizer)\n",
    "        self.gamma = gamma\n",
    "\n",
    "\n",
    "        # self.target_network = QNetwork(num_actions)\n",
    "        # self.target_network.compile(loss='mse', optimizer=self.optimizer)\n",
    "        \n",
    "    def select_action(self, state, epsilon):\n",
    "        if np.random.rand() < epsilon:\n",
    "            # Explore: choose a random action\n",
    "            return np.random.random(size=(1, MAX_STATES))\n",
    "        else:\n",
    "            # Exploit: choose the action with the highest Q-value\n",
    "            # Predict Q-values for the current state\n",
    "            # Select the action with the highest Q-value\n",
    "            q_values = self.model(state.reshape(1, MAX_STATES))\n",
    "            return q_values  \n",
    "        \n",
    "    def train(self, state: np.ndarray, action: np.ndarray, reward: float, next_state: np.ndarray, done: bool):\n",
    "\n",
    "        target = reward\n",
    "        if not done:\n",
    "            target = reward + self.gamma * np.max(self.model.predict(next_state.reshape(1, MAX_STATES))[0])\n",
    "        target_f = self.model.predict(next_state.reshape(1, MAX_STATES))\n",
    "        self.model.fit(state.reshape(1, MAX_STATES), target_f, epochs=1, verbose=0)\n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/vault/all/pwr/semestr_7/praca_dyplomowa/research/test3.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bserwer.local/vault/all/pwr/semestr_7/praca_dyplomowa/research/test3.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDNNAgent\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bserwer.local/vault/all/pwr/semestr_7/praca_dyplomowa/research/test3.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, parameters: t\u001b[39m.\u001b[39mSequence[\u001b[39mstr\u001b[39m], values: t\u001b[39m.\u001b[39mSequence[\u001b[39mstr\u001b[39m]):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bserwer.local/vault/all/pwr/semestr_7/praca_dyplomowa/research/test3.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m create_dnn_network(parameters, values)\n",
      "\u001b[1;32m/vault/all/pwr/semestr_7/praca_dyplomowa/research/test3.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bserwer.local/vault/all/pwr/semestr_7/praca_dyplomowa/research/test3.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDNNAgent\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bserwer.local/vault/all/pwr/semestr_7/praca_dyplomowa/research/test3.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, parameters: t\u001b[39m.\u001b[39mSequence[\u001b[39mstr\u001b[39m], values: t\u001b[39m.\u001b[39mSequence[\u001b[39mstr\u001b[39m]):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bserwer.local/vault/all/pwr/semestr_7/praca_dyplomowa/research/test3.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m create_dnn_network(parameters, values)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bserwer.local/vault/all/pwr/semestr_7/praca_dyplomowa/research/test3.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mlearning_rate)\n",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "class DNNAgent:\n",
    "    def __init__(self, parameters: t.Sequence[str], values: t.Sequence[str]):\n",
    "        self.model = create_dnn_network(parameters, values)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        self.loss = tf.losses.MeanSquaredError(reduction='sum')\n",
    "        self.model.compile(optimizer=self.optimizer, loss=self.loss)\n",
    "\n",
    "    def train(self, x: t.Dict[str, np.ndarray], y: t.Dict[str, np.ndarray], epochs: int):\n",
    "        return self.model.fit(x, y, 16, epochs=epochs, verbose=True)\n",
    "\n",
    "    def predict(self, x: t.Dict[str, np.ndarray]) -> t.Dict[str, np.ndarray]:\n",
    "        return self.model.predict(x, verbose=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = t.TypeVar('T')\n",
    "class Convertable(t.Generic[T], ABC):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def convert_to(self, x: T) -> float: ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def convert_from(self, x: float) -> T: ...\n",
    "\n",
    "class AnyConvertable(Convertable[t.Any]):\n",
    "    def convert_from(self, x: float) -> t.Any:\n",
    "        return x\n",
    "    \n",
    "    def convert_to(self, x: t.Any) -> float:\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeConvertable(Convertable[Time]):\n",
    "    SECONDS_IN_A_DAY = 60 * 60 * 24\n",
    "\n",
    "    def convert_to(self, x: Time) -> float:\n",
    "        seconds = timedelta(hours=x.hour, minutes=x.minute, seconds=x.second).total_seconds()\n",
    "        return np.cos(seconds * np.pi / self.SECONDS_IN_A_DAY)\n",
    "\n",
    "    def convert_from(self, _: float) -> Time:\n",
    "        raise AttributeError('convert_from is not needed')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager:\n",
    "    agents: t.Dict[str, DNNAgent] = {}\n",
    "    converters: t.Dict[str, Convertable] = {}\n",
    "\n",
    "    def __init__(self, inputs: t.Dict[str, Convertable], outputs: t.Sequence[str]):\n",
    "        self.converters = inputs\n",
    "\n",
    "        for name in outputs:\n",
    "            self.agents[name] = DNNAgent(inputs.keys(), [name])\n",
    "\n",
    "\n",
    "    def fit(self, x: t.Sequence[dict], y: t.Sequence[dict], epochs: int):\n",
    "        x = {i: np.array([self.converters[i].convert_to(d[i]) for d in x]) for i in self.converters.keys()}\n",
    "\n",
    "        for name, agent in self.agents.items():\n",
    "            y_new = {name: np.array([d[name] for d in y])}\n",
    "            print(f\"training {name}\")\n",
    "            agent.train(x, y_new, epochs=epochs)\n",
    "\n",
    "    def predict(self, x: t.Sequence[dict]):\n",
    "        x = {i: np.array([self.converters[i].convert_to(d[i]) for d in x]) for i in self.converters.keys()}\n",
    "        ret = {}\n",
    "        for _, agent in self.agents.items():\n",
    "            ret.update(agent.predict(x))\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate episodes here\n",
    "np.random.seed(0x1337)\n",
    "\n",
    "# IS_1 = np.array([False, False, False, False, False, False], dtype=float)\n",
    "# SHOULD_BE_1 = np.array([False, True, True, True, False, False], dtype=float)\n",
    "\n",
    "# IS_2 = np.array([False, False, False, False, False, True], dtype=float)\n",
    "# SHOULD_BE_2 = np.array([False, False, True, False, False, False], dtype=float)\n",
    "\n",
    "# IS_3 = np.array([True, True, False, False, False, False], dtype=float)\n",
    "# SHOULD_BE_3 = np.array([False, True, True, False, True, False], dtype=float)\n",
    "\n",
    "# EPISODES = []\n",
    "\n",
    "# for i in range(30):\n",
    "#     EPISODES.append((IS_1, SHOULD_BE_1))\n",
    "#     EPISODES.append((IS_2, SHOULD_BE_2))\n",
    "#     EPISODES.append((IS_3, SHOULD_BE_3))\n",
    "\n",
    "# ARR = np.array(EPISODES)\n",
    "get_random = lambda: float(np.random.random() > 0.5)\n",
    "get_time = lambda x: Time(hour=(hours := x // 3600), minute=(x - (hours * 3600)) // 60, second=x % 60)\n",
    "\n",
    "IS_1 = {'godzina': Time(10, 30), 'kuchnia': 0.0, 'salon': 0.0, 'swiatlo': 1.0, 'komputer': 0.0, 'wiatrolap': 0.0}\n",
    "SHOULD_BE_1 = {'kuchnia': 0.0, 'salon': 0.0, 'swiatlo': -1.0, 'komputer': 1.0, 'wiatrolap': 0.0}\n",
    "\n",
    "IS_2 = {'godzina': Time(14, 30), 'kuchnia': 1.0, 'salon': 0.0, 'swiatlo': 0.0, 'komputer': 0.0, 'wiatrolap': 0.0}\n",
    "SHOULD_BE_2 = {'kuchnia': -1.0, 'salon': 1.0, 'swiatlo': 1.0, 'komputer': 0.0, 'wiatrolap': 0.0}\n",
    "\n",
    "\n",
    "x, y = [], []\n",
    "for i in range(300):\n",
    "    x.append({'godzina': get_time(i * 250), 'kuchnia': 0.0, 'salon': 0.0, 'swiatlo': 1.0, 'komputer': 0.0, 'wiatrolap': 0.0})\n",
    "    y.append({'kuchnia': 0.0, 'salon': 0.0, 'swiatlo': 0.0, 'komputer': 0.0, 'wiatrolap': 0.0})\n",
    "\n",
    "    x.append(IS_1)\n",
    "    y.append(SHOULD_BE_1)\n",
    "\n",
    "    x.append(IS_2)\n",
    "    y.append(SHOULD_BE_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ModelManager({\n",
    "    'godzina': TimeConvertable(),\n",
    "    'kuchnia': AnyConvertable(),\n",
    "    'salon': AnyConvertable(),\n",
    "    'swiatlo': AnyConvertable(),\n",
    "    'komputer': AnyConvertable(),\n",
    "    'wiatrolap': AnyConvertable()},\n",
    "    ['kuchnia', 'salon', 'swiatlo', 'komputer', 'wiatrolap']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training kuchnia\n",
      "57/57 [==============================] - 1s 4ms/step - loss: 0.1208\n",
      "training salon\n",
      "57/57 [==============================] - 1s 4ms/step - loss: 0.2684\n",
      "training swiatlo\n",
      "57/57 [==============================] - 1s 4ms/step - loss: 1.7225\n",
      "training komputer\n",
      "57/57 [==============================] - 1s 4ms/step - loss: 1.5119\n",
      "training wiatrolap\n",
      "57/57 [==============================] - 1s 4ms/step - loss: 0.0520\n"
     ]
    }
   ],
   "source": [
    "agent.fit(x, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kuchnia': array([[-0.00990071]], dtype=float32),\n",
       " 'salon': array([[0.01189921]], dtype=float32),\n",
       " 'swiatlo': array([[-0.7892243]], dtype=float32),\n",
       " 'komputer': array([[0.83891654]], dtype=float32),\n",
       " 'wiatrolap': array([[-0.00027093]], dtype=float32)}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.predict([IS_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kuchnia': 0.0,\n",
       " 'salon': 0.0,\n",
       " 'swiatlo': -1.0,\n",
       " 'komputer': 1.0,\n",
       " 'wiatrolap': 0.0}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SHOULD_BE_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praca_dyplomowa-Y0s-XG3X",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
