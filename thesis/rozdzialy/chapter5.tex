\chapter{Implementacja}

\section{Dane wejściowe}
Krok przemiany danych wejściowych do wykorzystania w module został podzielony na dwa osobne etapy. Jeden z tych etapów, nazywany krokiem interpretacji, różni się w zależności od źródła skąd pochodzą dane. W zależności od tego, czy system korzysta z danych historycznych w procesie uczenia, czy korzysta z danych aktualnych w celu predykcji, inaczej przechodzą one proces interpretacji. Po etapie interpretacji jest krok transformacji i wygląda on tak samo dla każdego źródła niezależnie od typu.

% jest => następuje

\subsection{Interpretacja historyczna}
W przypadku danych ze źródła historycznego, system musi rozpoznawać epizody działań domowników w celu ich nauki. W tym celu, aby wygenerować zbiór danych uczących, algorytm przegląda posortowaną listę wydarzeń w czasie, celem określenia epizodów akcji. Począwszy od pierwszego wydarzenia, w dostępnej dla systemu historii, przegląda się ją w poszukiwaniu ciągu akcji o łącznym czasie nie większym, niż pewien z góry określony parametr nazwany \verb+EPISODE_DELTA+ od momentu wystąpienia pierwszej akcji w epizodzie. Ta wartość została wprowadzona w celu sprawdzenia, czy zmiana stanu w epizodzie się nie przedawniła. W przypadku, gdy jedno urządzenie zmienia swój stan kilkukrotnie w przeciągu jednego epizodu, brana jest tylko pod uwagę policzona zmiana i stan względem poprzedniego, przed liczonym epizodem. W tabeli (\ref{tab:znaleziony_epizod}) znajduje się znaleziony dla przykładowej historii epizod, a kolorem został zaznaczony znaleziony przez algorytm epizod akcji. 

Warto zauważyć, że wybrana długość tego parametru będzie mocno wpływała na liczność i wielkość epizodów. Wybranie zbyt krótkiego czasu epizodu będzie rozdzielać powiązane ze sobą czynności, ale będzie rozróżniała zmiany stanu tego samego urządzenia w czasie, a wybranie zbyt długiego czasu będzie łączyło kilka niezależnych akcji ze sobą, możliwie je ze sobą niwelując. Sprawia to, że wybranie optymalnej długości epizodu jest bardzo ważne, aby system mógł dostosować się do użytkownika.

\begin{table}
    \centering\caption{Tabela przedstawiająca działanie algorytmu szukania epizodów. \label{tab:znaleziony_epizod}}
    \begin{tabular}{|l|l|l|}
        \hline
        Urządzenie              & Stan       & Czas     \dnl
        \dots                   & \dots      & \dots    \nl
        \verb+światło kuchnia+  & \verb+on+  & 16:52:48 \nl 
        \rowcolor{lightgray}
        \verb+światło kuchnia+  & \verb+off+ & 17:32:12 \nl 
        \rowcolor{lightgray}
        \verb+klimatyzacja+     & \verb+17+  & 17:33:00 \nl 
        \rowcolor{lightgray}
        \verb+światło salon+    & \verb+on+  & 17:33:10 \nl
        \rowcolor{lightgray}
        \verb+telewizor salon+  & \verb+on+  & 17:33:15 \nl
        \verb+światło balkon+   & \verb+on+  & 19:32:42 \nl
        \dots                   & \dots      & \dots    \nl
    \end{tabular}
\end{table}

Do określenia działania, dla każdego innego typu urządzeń z osobna, skorzystano z abstrakcyjnej klasy \verb+DeviceHistoryGeneric+, opisującej strukturę funkcji jakie powinna dana klasa implementować w celu poprawnego działania. Abstrakcyjna funkcja na podstawie stanu urządzenia w momencie $t$, stanu urządzenia w momencie $k$ oraz czasu, do którego dany epizod powinien się skończyć, zwraca w postaci rzeczywistej liczby stan oraz przejście stanu dla danego epizodu w czasie. Pseudokod takiej funkcji został zawarty w listingu (\ref{listing:pseudo_get_past_state}). Warto zauważyć, że gdy nie ma poprzedniego stanu, tj. historia nie sięga na tyle wstecz, to kod musi obsługiwać wykrywanie obu wartości. W przypadku interpretacji prostych urządzeń nie jest to problemem, ponieważ jesteśmy w stanie wydedukować przejście stanu i aktualny stan na podstawie informacji pochodzącej z systemu. W przypadku gdy tej możliwości nie ma, pojedynczy błędny wynik powinien być zdecydowaną mniejszością po interpretacji reszty historii.

\begin{listing}
\begin{minted}[mathescape]{python}
def get_past_state(aktualny, poprzedni, do_momentu):
    wartość_stanu = 1.0 jeśli aktualny = "on" wpw 0.0
    wartość_przejścia = 0.0
    # Czy mamy historię na temat poprzedniego?
    jeśli poprzedni nie istnieje:
        # zakładamy, że zmiana stanu odbyła się dawno w historii
        return wartość_stanu, wartość_przejścia
    
    # Czy zmiana się nie przedawniła?
    jeśli poprzedni.czas_zmiany < do_momentu:
        wartość_przejścia = 1.0 jeśli aktualny = "on" wpw -1.0

    return wartość_stanu, wartość_przejścia
\end{minted}
\caption{Pseudokod funkcji interpretującej stany ze źródła historycznego dla typu urządzenia przełącznika stabilnego on/off.} \label{listing:pseudo_get_past_state}
\end{listing}

% Zebrane w ten sposób dane, zbierane są jako listy słowników języka Python w celu łatwiejszego 

\subsection{Interpretacja bieżąca} \label{subsec:interpretacja}
Bieżąca interpretacja akcji użytkownika wygląda bardzo podobnie do analizy historycznej. Informacja o aktualnym stanie całego systemu przechowywana jest przez moduł w pamięci. Podczas pracy systemu, mamy pewność, że system \textit{AppDaemon} zgłosi zmianę stanu tylko jednego urządzenia za każdym uruchomieniem asynchronicznej funkcji. Wiemy zatem, że musimy tylko obsłużyć zmianę stanu jednego urządzenia i zapisać jego stan do pamięci. Informacja o tym, jakie urządzenie zmieniło się do jakiego stanu będzie potrzebna w procesie predykcji, które będzie opisane w późniejszym etapie. Korzystając z tej samej klasy dla typu urządzenia co w przypadku interpretacji historycznej, w podobny sposób określamy stan i przejście stanu urządzenia. W tym wypadku ze względu na pewność, że dane urządzenie zmieniło swój stan dokładnie w momencie uruchomienia danej funkcji, obliczanie stanu i przejścia jest zdecydowanie prostsze, ponieważ nie trzeba rozważać przedawnienia się zmiany.

\subsection{Transformacja} \label{subsec:transformacja}
Po prawidłowej ekstrakcji zmian stanu, przed przekazaniem ich do sieci neuronowych, dane są dodatkowo przekształcane. W przypadku prostych urządzeń, typu przełącznik stabilny, ten proces nie wprowadza do danych żadnej zmiany. W przypadku bardziej skomplikowanych typów danych, takich jak zmienne temporalne wskazujące na np. dzień tygodnia czy porę dnia, przeprowadzane są pewne dodatkowe operacje rozkładające jedną konkretną informację na kilka różnych wartości, które lepiej będzie sieciom neuronowym powiązać z akcjami. W celu możliwości wprowadzenia rozszerzalności ponownie wykorzystano podejście obiektowe i skorzystano z klasy abstrakcyjnej. Zaproponowana klasa abstrakcyjna \verb+Convertable+ opisuje dwie funkcje, które dany konwerter danych musi zaimplementować. Jedna z nich opisuje przejście danych do wersji akceptowalnej przez sieci neuronowe, druga tłumaczy dane wygenerowane przez sieć neuronową do formy obsługiwanej przez resztę systemu. Jednym specjalnym przypadkiem takiego konwertowania danych, gdzie potrzebna jest zaimplementowana jedna z obu funkcji, jest przekazywanie zmiennych temporalnych do sieci.

W celu przekazania do sieci jak największej ilości rzeczywiście użytecznych informacji o porze dnia tak, aby była ona w stanie w swojej strukturze zapisać nawyki użytkownika, informacja o czasie jest podzielona. Podział jednej zmiennej czasowej odbywa się poprzez podzielenie jej na 24 różne informacje, gdzie każda z nich wskazuje na pewną wartość zależną od odległości indeksu danej zmiennej od godziny wydarzenia epizodu. Dokładniej, jest to wartość funkcji Gaussa dla wartości zależnej od indeksu, z parametrem $\mu$ ustawionym na moment w ciągu dnia podczas którego wydarzył się ten epizod.

Ważnym parametrem w przypadku funkcji Gaussa, poza parametrem $\mu$, jest parametr opisujący szerokość dzwona, w zastosowaniach statystycznych nazywany odchyleniem standardowym $\sigma$. W przypadku zastosowania obliczania wartości funkcji na podstawie czasu szerokość mówi nam o tym, jak bardzo akcje występujące o konkretnej porze dnia mogą być proponowane o innych podobnych godzinach. Ustawienie tego parametru zbyt wąsko spowoduje, że system będzie rozpoznawał wykonywanie konkretnych akcji o bardzo szczegółowych godzinach w ciągu dnia. Ustawienie go natomiast za szeroko będzie proponowało wykonywanie akcji nieadekwatnych do konkretnej pory dnia. Na obrazie (\ref{fig:time_param}) znajduje się przykładowy zarys wartości funkcji dla kilku konkretnych pór dnia, razem z zaznaczonymi dokładnymi przebiegami krzywizny dzwonowej. Każda z zaznaczonych godzin posiada inny parametr $\sigma$ w celu pokazania wpływu tego parametru na policzone wartości.

\begin{figure}
    \centering\includegraphics[width=1.00\textwidth]{img/time_param.pdf}
    \caption{Policzone wartości funkcji Gaussa wskazującej czas dla godziny 4:20:02, 13:37:21, 21:37:21.} \label{fig:time_param}
\end{figure}


\section{Sieci neuronowe}
Ze względu na wymóg osobnego przetwarzania wielu źródeł różnego typu w systemie, gdzie część z nich może kolejno zostać jeszcze podzielona na dalsze drobniejsze informacje, całość systemu została umieszczona w obiekt będący menedżerem. Głównym zadaniem menedżera jest agregowanie do jednego obiektu wielu konwerterów i agentów. Agent w tym systemie to obiekt z pewnymi z góry określonymi funkcjami opakowujący modele matematyczne dostarczone przez bibliotekę \textit{Tensorflow}, wykorzystywany do schowania za warstwą abstrakcji i detali implementacji \cite{book:programming_abstraction}, \cite{book:czysty_kod}. Takie wykorzystania menedżerów i obiektów agregujących przydaje się w przypadku tworzenia systemów dynamicznych, polegających na wczytywaniu i zapisywaniu obiektów do pamięci stałej. W przypadku tego modułu samouczącego daje to osobie rozszerzającej możliwości wykorzystania innych struktur niż wcześniej określono (\ref{tab:neural_network}), lub nawet wykorzystanie kompletnie innych metod predykcji w celu osiągnięcia danego celu.

\subsection{Dynamiczne tworzenie}
Bardzo wygodną możliwością udostępnianą przez bibliotekę \textit{Tensorflow} dla modeli sieci neuronowych są nazwane wyjścia oraz wejścia dla sieci. Pozwala to na dynamiczne tworzenie i eksploatację modeli bez żadnego bardzo skomplikowanego systemu przetwarzającego nazwę wejść na globalną pozycję w macierzy wejściowej. System w celu stworzenia modelu sieci neuronowej wykorzystuje obiekt \verb+Model+ udostępniany przez bibliotekę wykonawczą \textit{Tensorflow} -- Keras. Do stworzenia modelu sieci neuronowej korzysta się z informacji o nazwach wejść oraz nazwach wyjść. System podczas tworzenia nowej sieci tworzy listę warstw typu \verb+Input+ i każdej z nich przypisuje nazwę kolejnego wejścia do sieci, następnie każda z tych warstw, o kształcie \verb+(wielkość próbki, 1)+, jest do siebie dodawana wzdłuż drugiego wymiaru za pomocą warstwy typu \verb+Concatenate+. Powstała warstwa ma kształt \verb+(wielkość próbki, ilość wejść)+. W tym momencie kolejne warstwy dodaje się tak samo jak w przypadku zwykłego modelu funkcyjnego biblioteki \textit{Tensorflow} zgodnie z listą warstw podaną we wcześniejszym rozdziale (\ref{tab:neural_network}). Ostatnia warstwa, wyjściowa, tak jak w przypadku warstw wejściowych, generowana jest z listy nazw wyjść. Dynamiczne tworzenie wyjść, razem z modelem modularnej transformacji opisanej wcześniej, daje bardzo potężne narzędzie do sterowania domem.

\subsection{Serializowanie i deserializowanie}
Zapis oraz import danych w systemach komputerowych z formy istniejącej w pamięci do formatu, którą można zapisać na dysk jest bardzo rozległym zagadnieniem samym w sobie. W przypadku języka Python jest bardzo dużo sposobów wykonania tego zadania. Istnieje wbudowana biblioteka \textit{Pickle}, która zapisuje wprost bit po bicie zawartość części pamięci programu do pliku na dysku, jednak zapisuje też bardzo dużo redundantnych informacji nad którymi użytkownik nie ma kontroli. Istnieją rozwiązania, które w swojej formie są czytelne dla ludzi, ale osiągają mniejszą efektywność zapisu danych, takie jak \textit{XML} \cite{book:xml_handbook} czy \textit{JSON} \cite{book:json_for_begginers}. 

W wypadku zapisu i odczytu modeli matematycznych potrzebna jest obsługa trzech różnych informacji, które zostały wymienione wcześniej (\ref{subsec:nn}). Opis logicznej struktury sieci składa się z informacji o każdej z warstw. Każda z warstw zawiera informacje o jej wielkości, typie, rodzaju aktywacji, nazwach oraz informacji z jakimi warstwami sąsiaduje. Dostarczana przez \textit{Tensorflow} metoda dla obiektu modelu zwraca wszystkie te informacje w postaci słownika zawierającego tekst, listy oraz kolejne warstwy słowników. Klasa odpowiedzialna za model implementuje konstruktor \cite{book:czysty_kod}, który korzystając z informacji zawartych w opisanym słowniku odtwarza dokładną strukturę modelu. Sytuacja wygląda bardzo podobnie dla wag w modelu. Każda warstwa udostępnia funkcję zwracającą listę wszystkich ważnych dla danego typu warstwy parametrów, a druga, w obiekcie modelu, przyjmuje listę tych parametrów w celu odtworzenia wag.

W celu implementacji zapisywania i odczytu danych z dysku skorzystano z wbudowanej w Python biblioteki obsługującej pliki \verb+.zip+ oraz z metody serializacji \textit{JSON}. Do obsługi procesu zapisu i odczytu stworzono klasę \verb+ModelSerializer+, implementującą metody potrzebne do skorzystania z danego obiektu jako menedżera kontekstu języka Python \cite{book:learning_python}. Taki sposób implementacji zapewni, że wszystkie wymagane operacje na pliku i buforach w pamięci zostaną wykonane bez ingerencji użytkownika, co pozwoli na uniknięcie błędów. Stworzony obiekt dostarcza dwie główne metody. Jedna z nich służąca do odczytu i odtworzenia całej struktury menedżerów do takiej wykorzystanej przez moduł oraz drugiej, wykorzystywanej do zapisu całego menedżera do pamięci stałej, które działają analogicznie w odwrotnym kierunku.

Pewną emergentną zaletą takiego połączenia serializowania za pomocą \textit{JSON} wewnątrz kompresowalnego archiwum plików jest zmniejszenie miejsca, które zajmują wszystkie modele na dysku o nawet 57\%. Opis wytworzonego w ten sposób przykładowego archiwum znajduje się w listingu (\ref{listing:zipinfo}).

\begin{listing}
\begin{minted}{text}
Zip file size: 698977 bytes, number of entries: 19
?rw-------  2.0 unx     8626 b- 23-Nov-22 10:47 kuchnia/declaration.json
?rw-------  2.0 unx   264887 b- 23-Nov-22 10:47 kuchnia/weights.json
?rw-------  2.0 unx       59 b- 23-Nov-22 10:47 kuchnia/meta/info.json
?rw-------  2.0 unx     8640 b- 23-Nov-22 10:47 ekspres/declaration.json
?rw-------  2.0 unx   265319 b- 23-Nov-22 10:47 ekspres/weights.json
?rw-------  2.0 unx       59 b- 23-Nov-22 10:47 ekspres/meta/info.json
?rw-------  2.0 unx     8646 b- 23-Nov-22 10:47 salon/declaration.json
?rw-------  2.0 unx   265341 b- 23-Nov-22 10:47 salon/weights.json
?rw-------  2.0 unx       59 b- 23-Nov-22 10:47 salon/meta/info.json
?rw-------  2.0 unx     8648 b- 23-Nov-22 10:47 telewizor/declaration.json
?rw-------  2.0 unx   265556 b- 23-Nov-22 10:47 telewizor/weights.json
?rw-------  2.0 unx       59 b- 23-Nov-22 10:47 telewizor/meta/info.json
?rw-------  2.0 unx     8656 b- 23-Nov-22 10:47 balkon/declaration.json
?rw-------  2.0 unx   265197 b- 23-Nov-22 10:47 balkon/weights.json
?rw-------  2.0 unx       59 b- 23-Nov-22 10:47 balkon/meta/info.json
?rw-------  2.0 unx     8658 b- 23-Nov-22 10:47 sypialnia/declaration.json
?rw-------  2.0 unx   265469 b- 23-Nov-22 10:47 sypialnia/weights.json
?rw-------  2.0 unx       59 b- 23-Nov-22 10:47 sypialnia/meta/info.json
?rw-------  2.0 unx      273 b- 23-Nov-22 10:47 info.json
19 files, 1644270 bytes uncompressed, 696557 bytes compressed:  57.6%
\end{minted}
\caption{Listowanie plików wewnątrz archiwum zawierajacego przykładowe modele sieci pochodzące z programu zipinfo.} \label{listing:zipinfo}
\end{listing}

% todo: powtarza mi sie system, w drugi mi trzecim akapicie
\section{Sterowanie systemem}
Gdy dane o stanie z dołączonymi innymi informacjami temporalnymi przejdą przez cały system i jest zwracana predykcja, system musi podjąć decyzję czy to, co aktualnie użytkownik tych urządzeń wykonuje, jest zgodne z tym co system przewiduje. Jak wcześniej zostało opisane, system stara się przewidzieć następną zmianę stanu na podstawie przekazanych do modelu wartości o aktualnym stanie. Aby system był jak najbardziej wygodny dla użytkownika, zdecydowano na dopełnianie akcji użytkownika, zamiast wykonywanie zadań autonomicznie. Sprawia to, że proces wyboru czasu kiedy system powinien dokończyć daną akcję staje się bardzo skomplikowany.

W celu wykonywania tylko tych akcji, które są w danym momencie zgodne z zamiarem użytkownika, porównywane są predykcje sieci neuronowych z aktualną zmianą na którą moduł reaguje. Dane wejściowe policzone z interpretacji bieżącej (\ref{subsec:interpretacja}) porównywane są z przewidywanymi przez system. Jeśli zamiar użytkownika jest wspólny z tym, co moduł chce wykonać, moduł podejmuje decyzję o dokończeniu przewidzianego epizodu akcji. Porównanie zamiaru jest trywialne i sprawdza podobieństwo obliczonego aktualnego przejścia stanu dla danego urządzenia z tym, które powstało z predykcji. Korzystając z informacji o aktualnym stanie oraz przewidzianej zmiany generowane są zapytania do \textit{HomeAssistant}, mające na celu sprowadzenie środowiska do nowego stanu.

Do stworzenia funkcjonalności cofania niechcianych akcji wykorzystano istniejące w systemie rozwiązania. W momencie gdy system wykonuje za użytkownika dowolny epizod, zapisywany jest stan tuż przed wysłaniem do środowiska polecenia o zmianie. Gdy użytkownik zdecyduje, że wykonana przez system zmiana nie odpowiada jego oczekiwaniom i poinformuje o tym moduł, to, korzystając z poprzedniego oraz aktualnego stanu, moduł wygeneruje zapytania sprowadzające system do stanu bez przewidzianej zmiany. Na podstawie wyliczonej docelowej zmiany oraz aktualnego stanu środowiska wygeneruje zapytanie mające na celu usunięcie niewłaściwej predykcji.

\section{Formatowanie danych uczących} \label{sec:dane_uczace}
Uczenie sieci neuronowych z danych pochodzących z historii HomeAssistant często samo w sobie jest niewystarczające. Sieci mimo tego, że uczone są na dużej ilości danych temporalnych, poza samymi stanami systemu, nie są w stanie nauczyć się konkretnych epizodów. W tym celu zaproponowano generowanie dodatkowych danych uczących na podstawie wygenerowanych informacji o przejściach, aby poprawić celność systemu.

Algorytm generowania danych tworzy dodatkowe informacje wejściowe zawierające brak zmiany stanu dla konkretnego stanu systemu o innej porze dnia, niż wtedy kiedy dany epizod jest wykonywany. Aby to umożliwić funkcja tworzy dwa słowniki, jeden dla którego wartościami są listy zawierające czas pewnego wydarzenia, druga dla której wartości to zbiory zmiany stanów. W obu tych słownikach kluczami są stany, dla którego rozpatrywany jest czas czy zmiana. Dalej, dla każdego czasu kiedy dane zdarzenie się wydarzyło, czyli dla elementów w pierwszym z obu słowników, generowany jest estymator jądrowy danego wydarzenia. W tym celu wykorzystano sumę rozkładów normalnych. Następnie wygenerowany estymator jest odwracany i progowany. Wszystkie wartości powyżej lub poniżej pewnego przedziału są spłaszczane do wartości brzegowych, a następnie przekształcane i skalowane tak, aby suma pola pod wykresem wynosiła 1, a najmniejszą wartością było 0. Proces ten został zobrazowany na obrazie (\ref{fig:transform}). Korzystając z tak wygenerowanego estymatora znormalizowanego i funkcji losującej wartość z przedziału pod warunkiem macierzy prawdopodobieństw, dostarczonej przez \textit{numpy}, generowany jest zestaw zerowych przejść z czasem pochodzącym z tego rozkładu, a następnie dołączany do listy danych do uczenia. Ten proces ma na celu stworzenie listy dodatkowych danych bez żadnej zmiany dla konkretnego stanu o innej porze w ciągu dnia, tak aby sieci neuronowe powiązały konkretny stan w ciągu dnia z konkretną porą dla danej odpowiedzi. Tak stworzona lista dla konkretnych stanów jest bardzo rzadka -- posiada same zera w przejściach stanów -- co może negatywnie wpłynąć na wynik uczenia sieci neuronowych. W tym celu, aby zrównoważyć stosunek ilości pustych akcji do tych rzeczywistych, do listy danych uczących dodawane są kolejne dane. Dane te losowane są z drugiego słownika dla konkretnie obsługiwanego stanu systemu i dodawane do danych uczących, czyli dopisywane są kopie danego rzeczywistego wydarzenia.

\begin{figure}[t]
    \centering\includegraphics[width=1.00\textwidth]{img/transformation.pdf}
    \caption{Wizualizacja wygenerowanego estymatora jądrowego bez progowania oraz przebieg gotowej funkcji gęstości prawdopodobieństwa.} \label{fig:transform}
\end{figure}

\section{Napotkane problemy}
Ta sekcja ma na celu opisanie zaistniałych problemów podczas implementowania modułu. Są to trudności związane z przewidzeniem, jak zachowywać się będzie gotowy system bez żadnej istniejącej implementacji ani prototypu, ale także związane ze zwykłą naturą programistyczną.

\subsection{Reprezentacja czasu} \label{subsec:reprezentacja_czasu}
Reprezentacja czasu w modelach uczenia maszynowego jest bardzo ważna. Wysoka i mała rzadkość danych sprawia, że modele potrzebują bardzo dużo obserwacji aby rzeczywiście były w stanie generować predykcje zgodne z prawdą \cite{curse_of_dimensionality}. Podczas implementacji modułu początkowo wszystkie dane temporalne reprezentowane były jako kosinusoida znormalizowanej pory dnia. Wykorzystanie funkcji trygonometrycznej było uwarunkowane jej okresowością i spokojnym przebiegiem przez całą rozpatrywaną domenę. Podczas testów prototypu, bez dodatkowej funkcji tworzącej nowe dane uczące (\ref{sec:dane_uczace}), modele mimo testów z różnymi parametrami nie były w stanie dopasować się do obserwacji. Zdecydowano wówczas o rozbiciu danych temporalnych do zdecydowanie większej i rzadszej formy, zainspirowanej metodami radialnych funkcji bazowych, opisanej w (\ref{subsec:transformacja}). Testy prototypu przynosiły zdecydowanie lepsze wyniki, ale wciąż nie były one wystarczająco zadowalające. Kolejnym etapem który podjęto było stworzenie wyżej opisanej funkcji generującej sztuczne dane. Dopiero od tego momentu sieć uczyła się obserwacji w dostatecznym stopniu. Po wstępnych badaniach okazało się, że poprzednio stworzone rozwiązanie korzystające z funkcji trygonometrycznej i, w dalszej iteracji, złożenie sinusoidy i kosinusoidy w połączeniu z funkcją, również dają zadowalające wyniki. Zdecydowano zatem o pozostawieniu części kodu, odpowiedzialnego za pozostały sposób transformacji danych, jako możliwej alternatywy dla użytkownika.

\subsection{Obraz Docker -- AppDaemon}
W celu minimalizacji reimplementacji często używanych i powtarzanych funkcji w językach programowania korzysta się ze standardowych bibliotek, które zapewniają szkielet podstawowych funkcjonalności programowania \cite{book:cstdl}. Pomaga to uniknięcia części błędów i zmniejszenia wielkości powstałego oprogramowania. Każda rodzina systemów operacyjnych opiera swoją strukturę na innej bibliotece, które zapewniają w praktyce taką samą funkcjonalność inną implementacją i konwencją, zatem programy nie są kompatybilne między rodzinami systemów operacyjnych, a czasami nawet różnymi dystrybucjami tego samego systemu operacyjnego. Przykładem takiego oprogramowania, które nie jest kompatybilne między dystrybucjami tej samej rodziny systemów, jest \textit{Tensorflow}, który jest dostępny w gotowej do zainstalowania wersji, między innymi dla systemów wspierających \textit{glibc}. W celu stworzenia modułu samouczącego należało połączyć ze sobą obraz \textit{AppDaemon} wraz z \textit{Tensorflow}, które w oryginalnych konfiguracjach korzystają z zupełnie innych bibliotek standardowych języka C \cite{page:alpine_linux} \cite{page:ad_dockerfile}. W celu rozwiązania tego problemu stworzono własny obraz modułu \textit{AppDaemon}, który powstał na bazie systemu wspierającego \textit{glibc}. Podczas tworzenia instalowana jest biblioteka \textit{Tensorflow} oraz opisywany w tej pracy moduł samouczący.

% https://www.alpinelinux.org/about/

% Stworzony, gotowy obraz w internecie modułu AppDaemon bazuje na dystrybucji Linux'a nazywanej Alpine Linux, która opiera się na implementacji musl libc \cite{page:alpine_linux}.
% Gotowe, skompilowane wersje tego oprogramowania są dostępne do pobrania dla systemów korzystających z glibc jako biblioteki standardowej języka C.

% wykorzystanie warstw abstrakcji jest lepsze ...